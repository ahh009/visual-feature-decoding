{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8022ba01-1571-4ef6-9414-4a090249dae2",
   "metadata": {},
   "source": [
    "# This notebook is for cleaning the BOLD data associated with the HCP movie-watching subjects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc6dbb-81cd-4e10-8c57-5748c948b228",
   "metadata": {},
   "source": [
    "## 1. BOLD processing for encoding models\n",
    "Section 1 processes BOLD into format required for encoding models, using only lh and rh.  \n",
    "If you want to look at subcortical voxels too, you'll need to add that in when generating Y_test and Y_train.  \n",
    "\n",
    "Ending framework is as follows:  \n",
    "training data (TR, vertices)  \n",
    "testing data (repeats, TR, vertices)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82ae6a-d801-4be9-b804-dcbb0b1ed773",
   "metadata": {},
   "source": [
    "import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793bdc11-efec-4a72-9b09-f46ef459fe06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import neuropythy as ny\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b88201-145b-4f02-b7fe-c921b13a2a4e",
   "metadata": {},
   "source": [
    "create bold dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b41f3096-27f0-4287-a749-eb5529b17a10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "bolddictionary = dict()\n",
    "movies = ['MOVIE1_7T_AP', 'MOVIE2_7T_PA', 'MOVIE3_7T_PA', 'MOVIE4_7T_AP']\n",
    "\n",
    "for i in movies:\n",
    "    filename = f'/home/jovyan/shared/HCP/115825/MNINonLinear/Results/tfMRI_{i}/tfMRI_{i}_Atlas_1.6mm_MSMAll_hp2000_clean.dtseries.nii'\n",
    "    cii = ny.load(filename)\n",
    "    (lh_bold, rh_bold, subcortex_bold) = ny.hcp.cifti_split(cii)\n",
    "    \n",
    "    bolddictionary[f'{i}'] = {'lh_bold':lh_bold, 'rh_bold':rh_bold, 'subcortex_bold':subcortex_bold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b361c6cf-b7af-48d1-90e6-065e398f190f",
   "metadata": {},
   "source": [
    "select only TRs that correspond to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb456d0-dfe0-4a95-aa22-5437bb308c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_filepath = '/home/jovyan/visual-feature-decoding/extract_features/feature.json'\n",
    "\n",
    "with open(json_filepath) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# load in json data\n",
    "for stimuli, stimuli_data in data.items():\n",
    "        movies = stimuli_data['movies']\n",
    "        savepath = stimuli_data['savepath']\n",
    "        TRs = stimuli_data['TRs']\n",
    "        \n",
    "        y_train_lh = []\n",
    "        y_train_rh = []\n",
    "        y_train_subcortex = []\n",
    "        y_test_lh = []\n",
    "        y_test_rh = []\n",
    "        y_test_subcortex = []\n",
    "        \n",
    "        for movie, run_TRs in TRs.items():\n",
    "            movie_feature = movie[3:-7]\n",
    "            for keys, values in bolddictionary.items():\n",
    "                for keyx, region in values.items():\n",
    "                    movie_bold = keys[:-6]\n",
    "                    if movie_feature == movie_bold:\n",
    "                        for key, run in run_TRs.items():\n",
    "                            if key.startswith('train'):\n",
    "                                if keyx == 'lh_bold':\n",
    "                                    y_train_lh.append(region[run[0]:run[1],:])\n",
    "                                if keyx == 'rh_bold':\n",
    "                                    y_train_rh.append(region[run[0]:run[1],:])\n",
    "                                if keyx == 'subcortex_bold':\n",
    "                                    y_train_subcortex.append(region[run[0]:run[1],:])\n",
    "                            if key.startswith('test'):\n",
    "                                if keyx == 'lh_bold':\n",
    "                                    y_test_lh.append(region[run[0]:run[1],:])\n",
    "                                if keyx == 'rh_bold':\n",
    "                                    y_test_rh.append(region[run[0]:run[1],:])\n",
    "                                if keyx == 'subcortex_bold':\n",
    "                                    y_test_subcortex.append(region[run[0]:run[1],:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae6d976-c477-4c05-8d2a-d3804c8c8db0",
   "metadata": {},
   "source": [
    "Create Y_train and Y_test dictionaries, and flatten into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ca2b31-7305-439f-9a02-1dc0c734767d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_train_regions = dict()\n",
    "trainlist = {'y_train_rh': y_train_rh, 'y_train_lh': y_train_lh, 'y_train_subcortex': y_train_subcortex}\n",
    "\n",
    "for name, train in trainlist.items():\n",
    "    intermediate = np.concatenate(train, axis=0)\n",
    "    Y_train_regions[f'{name}'] = intermediate\n",
    "    \n",
    "Y_test_regions = dict()\n",
    "testlist = {'y_test_rh': y_test_rh, 'y_test_lh': y_test_lh, 'y_test_subcortex': y_test_subcortex}\n",
    "\n",
    "for name, test in testlist.items():\n",
    "    intermediate = np.stack(test)\n",
    "    Y_test_regions[f'{name}'] = intermediate\n",
    "    \n",
    "# flatten to numpy arrays\n",
    "Y_test = np.concatenate((Y_test_regions['y_test_rh'], Y_test_regions['y_test_lh']), axis=2)\n",
    "Y_train = np.concatenate((Y_train_regions['y_train_rh'], Y_train_regions['y_train_lh']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b984288-b0f0-4e3d-a256-2c1d2d7c3f7e",
   "metadata": {},
   "source": [
    "info for saving with file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a3b57b3-e410-4fdb-87f2-c06198499094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info = 'Y_test is the concatenation of rh and lh, rh first. this bold data is cleaned for encoding models!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597a555-c382-4000-a18e-32d426b667bc",
   "metadata": {},
   "source": [
    "save out bold!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dab318-cd48-4006-aa35-59e72b0c830e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez('/home/jovyan/workingdirectory/encodingmodel_BOLD.npz', Y_train=Y_train, Y_test=Y_test, info=info)\n",
    "Y_train.shape, Y_test.shape, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1875643d-c39d-410c-ab46-e667a1441273",
   "metadata": {},
   "source": [
    "# 2. BOLD processing for classifier\n",
    "This section is for processing the BOLD into a pandas dataframe with columns subject, TR, BOLD, hemisphere, and features (if added)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf25b1-1e05-4075-97c9-2d80319d754f",
   "metadata": {},
   "source": [
    "import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc282984-a9e5-4a08-8511-f2c6d8737ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import neuropythy as ny\n",
    "import json\n",
    "import nibabel as nib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a015f-706b-4c7b-8e52-091fa439c328",
   "metadata": {},
   "source": [
    "load in the ROIs for the subject. this is using HCP's surface, FSLR? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87cf9408-bf86-492b-8cff-41745591d363",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "ROI = nib.load('/home/jovyan/shared/HCP/115825/MNINonLinear/fsaverage_LR59k/115825.aparc.59k_fs_LR.dlabel.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc936dea-4ab0-4b61-a5dd-6b27e72aeefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(lh_roi, rh_roi, subcortex_roi) = ny.hcp.cifti_split(ROI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020eedc9-8b06-4d4c-9061-c5ba13349c64",
   "metadata": {},
   "source": [
    "I went through visualizing each ROI to identify which ones are in visual cortex. the ```visual_ROIs``` list is the list of ROIs that make up visual cortex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e6d4857-9c29-4321-ad49-6b2bfb032c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visual_ROIs = [5, 8, 11, 13, 21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97341d6d-c80b-4ed7-b909-940e44a6527a",
   "metadata": {},
   "source": [
    "Now let's merge them to get a huge visual cortex mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9171245b-c665-4cb3-9384-25b806603425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hemi = {'lh':lh_roi[0], 'rh':lh_roi[0]}\n",
    "\n",
    "visualcortexmask = dict()\n",
    "for h, roi in hemi.items():\n",
    "    for ROI in visual_ROIs:\n",
    "        result = ((roi == 5) | (roi == 8) | (roi == 11) | (roi == 13) | (roi == 21))\n",
    "        visualcortexmask[f\"{h}\"] = result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb837edb-20bd-478f-a81f-5e11a9406e48",
   "metadata": {},
   "source": [
    "Let's visualize on the surface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df8b5a56-2cd1-447f-98df-73eb20982392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a785e58840423e99b46910a63de0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(box_center=[0.5, 0.5, 0.5], box_size=[1.0, 1.0, 1.0], camera=PerspectiveCamera(fov=0.644570721372708, p…"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = ny.hcp_subject('/home/jovyan/shared/HCP/115825')\n",
    "ny.cortex_plot(sub.hemis['lh_LR59k'], color='r', mask=(visualcortexmask['lh']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d679378-338a-4995-942c-bc9847111009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67fb03c5d2c4ada865d4635a102498c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(box_center=[0.5, 0.5, 0.5], box_size=[1.0, 1.0, 1.0], camera=PerspectiveCamera(fov=0.644570721372708, p…"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = ny.hcp_subject('/home/jovyan/shared/HCP/115825')\n",
    "ny.cortex_plot(sub.hemis['rh_LR59k'], color='r', mask=(visualcortexmask['lh']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddda10-9d7a-4220-aa09-947e383c5079",
   "metadata": {},
   "source": [
    "Great!  \n",
    "Now let's extract the BOLD data for each movie.\n",
    "  \n",
    "First we need to just load in the BOLD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7091dcc4-c564-4a58-85aa-3fba5df7a5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "bolddictionary = dict()\n",
    "movies = ['MOVIE1_7T_AP', 'MOVIE2_7T_PA', 'MOVIE3_7T_PA', 'MOVIE4_7T_AP']\n",
    "\n",
    "for i in movies:\n",
    "    filename = f'/home/jovyan/shared/HCP/115825/MNINonLinear/Results/tfMRI_{i}/tfMRI_{i}_Atlas_1.6mm_MSMAll_hp2000_clean.dtseries.nii'\n",
    "    cii = ny.load(filename)\n",
    "    (lh_bold, rh_bold, subcortex_bold) = ny.hcp.cifti_split(cii)\n",
    "    \n",
    "    bolddictionary[f'{i}'] = {'lh_bold':lh_bold, 'rh_bold':rh_bold, 'subcortex_bold':subcortex_bold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254ce3a-d335-4aec-914e-fd40035f74f4",
   "metadata": {},
   "source": [
    "Now that we have the bold dictionary loaded in for each movie, we need to extract only the TRs for when the train or test movies were playing.  \n",
    "(Keep in mind the following script uses the feature.json used for feature extraction!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff85502f-4e7b-4709-88a3-aa152516a71e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_filepath = '/home/jovyan/visual-feature-decoding/extract_features/feature.json'\n",
    "\n",
    "with open(json_filepath) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# load in json data\n",
    "for stimuli, stimuli_data in data.items():\n",
    "        movies = stimuli_data['movies']\n",
    "        savepath = stimuli_data['savepath']\n",
    "        TRs = stimuli_data['TRs']\n",
    "        \n",
    "        y_train_lh = []\n",
    "        y_train_rh = []\n",
    "        y_train_subcortex = []\n",
    "        y_test_lh = []\n",
    "        y_test_rh = []\n",
    "        y_test_subcortex = []\n",
    "        \n",
    "        for movie, run_TRs in TRs.items():\n",
    "            movie_feature = movie[3:-7]\n",
    "            for keys, values in bolddictionary.items():\n",
    "                for keyx, region in values.items():\n",
    "                    movie_bold = keys[:-6]\n",
    "                    if movie_feature == movie_bold:\n",
    "                        for key, run in run_TRs.items():\n",
    "                            if key.startswith('train'):\n",
    "                                if keyx == 'lh_bold':\n",
    "                                    y_train_lh.append(region[run[0]:run[1],:])\n",
    "                                if keyx == 'rh_bold':\n",
    "                                    y_train_rh.append(region[run[0]:run[1],:])\n",
    "                                if keyx == 'subcortex_bold':\n",
    "                                    y_train_subcortex.append(region[run[0]:run[1],:])\n",
    "                            if key.startswith('test'):\n",
    "                                if keyx == 'lh_bold':\n",
    "                                    y_test_lh.append(region[run[0]:run[1],:])\n",
    "                                if keyx == 'rh_bold':\n",
    "                                    y_test_rh.append(region[run[0]:run[1],:])\n",
    "                                if keyx == 'subcortex_bold':\n",
    "                                    y_test_subcortex.append(region[run[0]:run[1],:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729d3ec-bfce-4725-8b86-8597d2638b78",
   "metadata": {},
   "source": [
    "Now we're moving them from a list to a concatenated numpy array/matrix. I'm sure this could be done in one step, but I did it in two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00dbf424-64d8-4c93-be5c-12793e6a9558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training data concatenation\n",
    "Y_train_regions = dict()\n",
    "trainlist = {'y_train_rh': y_train_rh, 'y_train_lh': y_train_lh, 'y_train_subcortex': y_train_subcortex}\n",
    "\n",
    "for name, train in trainlist.items():\n",
    "    intermediate = np.concatenate(train, axis=0)\n",
    "    Y_train_regions[f'{name}'] = intermediate\n",
    "\n",
    "# test data concatenation\n",
    "Y_test_regions = dict()\n",
    "testlist = {'y_test_rh': y_test_rh, 'y_test_lh': y_test_lh, 'y_test_subcortex': y_test_subcortex}\n",
    "\n",
    "for name, test in testlist.items():\n",
    "    intermediate = np.stack(test)\n",
    "    Y_test_regions[f'{name}'] = intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ad185-9a4b-4ff2-8423-a8f2467a76c9",
   "metadata": {},
   "source": [
    "Now we can insert features if we have them! Load them in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e49f559-f871-49cc-b8d4-e4d30e711e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"/home/jovyan/workingdirectory/me_features_all.npz\", allow_pickle=True)['x_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53178e53-b763-4551-a7ea-332e01f4258a",
   "metadata": {},
   "source": [
    "They're saved out in features x TRs format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aaec65fe-ec7a-4f9b-b6b9-a6a3b7fb201c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1580, 2885)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f11d28-3cbe-4f94-9e9e-3ef05cf6d251",
   "metadata": {},
   "source": [
    "Now let's mask our BOLD with the visual cortex mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca38409a-bcb6-43f2-b3b6-ed1122fc00cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rhemi = Y_train_regions['y_train_rh'][:,visualcortexmask['rh']]\n",
    "lhemi = Y_train_regions['y_train_lh'][:,visualcortexmask['lh']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d0171-b98b-4fb3-a1ad-ba54f604e716",
   "metadata": {},
   "source": [
    "Convert all data to the pandas dataframe requested by the classifier team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d10c1905-1690-48a1-a852-640beb890760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of arrays where each row is a visual-cortex-sized vector\n",
    "array_list = [row for row in rhemi]\n",
    "num_TRs = rhemi.shape[0]\n",
    "\n",
    "# Create a DataFrame with a single column for the array vectors\n",
    "rh_df = pd.DataFrame({'BOLD': array_list})\n",
    "rh_df['subject'] = 115825\n",
    "rh_df['hemisphere'] = 'RH'\n",
    "rh_df['TR'] = range(1, num_TRs+1)\n",
    "featurelist = [row for row in X_train.T]\n",
    "rh_df['motionenergy'] = featurelist\n",
    "\n",
    "array_list = [row for row in lhemi]\n",
    "\n",
    "# Create a DataFrame with a single column for the array vectors\n",
    "lh_df = pd.DataFrame({'BOLD': array_list})\n",
    "lh_df['subject'] = 115825\n",
    "lh_df['hemisphere'] = 'LH'\n",
    "lh_df['TR'] = range(1, num_TRs+1)\n",
    "featurelist = [row for row in X_train.T]\n",
    "lh_df['motionenergy'] = featurelist\n",
    "\n",
    "combined_df = pd.concat([rh_df, lh_df], ignore_index=True)\n",
    "new_order = ['subject', 'TR', 'BOLD', 'hemisphere', 'motionenergy']\n",
    "visualcortex_bold = combined_df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fcbaece8-0aad-4a7f-9cb0-82f4b34c8a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>TR</th>\n",
       "      <th>BOLD</th>\n",
       "      <th>hemisphere</th>\n",
       "      <th>motionenergy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115825</td>\n",
       "      <td>1</td>\n",
       "      <td>[10239.255859375, 11871.8603515625, 11993.7880...</td>\n",
       "      <td>RH</td>\n",
       "      <td>[4.938675064525029, 6.132030972822991, 3.48840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115825</td>\n",
       "      <td>2</td>\n",
       "      <td>[10003.9130859375, 12004.6943359375, 11882.559...</td>\n",
       "      <td>RH</td>\n",
       "      <td>[5.561072885210463, 6.815657111866309, 4.02723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115825</td>\n",
       "      <td>3</td>\n",
       "      <td>[10490.705078125, 11965.4453125, 11899.5048828...</td>\n",
       "      <td>RH</td>\n",
       "      <td>[5.613112008355411, 6.868877894818759, 4.11684...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115825</td>\n",
       "      <td>4</td>\n",
       "      <td>[10201.9267578125, 12261.61328125, 12231.50097...</td>\n",
       "      <td>RH</td>\n",
       "      <td>[5.613940827450448, 6.869078405301136, 4.11771...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115825</td>\n",
       "      <td>5</td>\n",
       "      <td>[10609.5888671875, 11908.8857421875, 12012.480...</td>\n",
       "      <td>RH</td>\n",
       "      <td>[5.614502650536449, 6.868823924129038, 4.11847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>115825</td>\n",
       "      <td>2881</td>\n",
       "      <td>[10969.7568359375, 12294.6904296875, 12354.027...</td>\n",
       "      <td>LH</td>\n",
       "      <td>[5.125499386899641, 6.301422471960991, 3.64851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>115825</td>\n",
       "      <td>2882</td>\n",
       "      <td>[11257.3076171875, 12597.392578125, 12592.3007...</td>\n",
       "      <td>LH</td>\n",
       "      <td>[5.308308159740405, 6.335240703080079, 3.79914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>115825</td>\n",
       "      <td>2883</td>\n",
       "      <td>[11080.234375, 12805.1298828125, 12594.9638671...</td>\n",
       "      <td>LH</td>\n",
       "      <td>[5.334164146556728, 6.332840959096909, 3.84412...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>115825</td>\n",
       "      <td>2884</td>\n",
       "      <td>[11247.6865234375, 12280.365234375, 12220.8710...</td>\n",
       "      <td>LH</td>\n",
       "      <td>[5.300586182654747, 6.323548374880514, 3.83521...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>115825</td>\n",
       "      <td>2885</td>\n",
       "      <td>[10938.349609375, 12419.0625, 12395.5068359375...</td>\n",
       "      <td>LH</td>\n",
       "      <td>[5.261199259726798, 6.320932059244072, 3.83276...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5770 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject    TR                                               BOLD  \\\n",
       "0      115825     1  [10239.255859375, 11871.8603515625, 11993.7880...   \n",
       "1      115825     2  [10003.9130859375, 12004.6943359375, 11882.559...   \n",
       "2      115825     3  [10490.705078125, 11965.4453125, 11899.5048828...   \n",
       "3      115825     4  [10201.9267578125, 12261.61328125, 12231.50097...   \n",
       "4      115825     5  [10609.5888671875, 11908.8857421875, 12012.480...   \n",
       "...       ...   ...                                                ...   \n",
       "5765   115825  2881  [10969.7568359375, 12294.6904296875, 12354.027...   \n",
       "5766   115825  2882  [11257.3076171875, 12597.392578125, 12592.3007...   \n",
       "5767   115825  2883  [11080.234375, 12805.1298828125, 12594.9638671...   \n",
       "5768   115825  2884  [11247.6865234375, 12280.365234375, 12220.8710...   \n",
       "5769   115825  2885  [10938.349609375, 12419.0625, 12395.5068359375...   \n",
       "\n",
       "     hemisphere                                       motionenergy  \n",
       "0            RH  [4.938675064525029, 6.132030972822991, 3.48840...  \n",
       "1            RH  [5.561072885210463, 6.815657111866309, 4.02723...  \n",
       "2            RH  [5.613112008355411, 6.868877894818759, 4.11684...  \n",
       "3            RH  [5.613940827450448, 6.869078405301136, 4.11771...  \n",
       "4            RH  [5.614502650536449, 6.868823924129038, 4.11847...  \n",
       "...         ...                                                ...  \n",
       "5765         LH  [5.125499386899641, 6.301422471960991, 3.64851...  \n",
       "5766         LH  [5.308308159740405, 6.335240703080079, 3.79914...  \n",
       "5767         LH  [5.334164146556728, 6.332840959096909, 3.84412...  \n",
       "5768         LH  [5.300586182654747, 6.323548374880514, 3.83521...  \n",
       "5769         LH  [5.261199259726798, 6.320932059244072, 3.83276...  \n",
       "\n",
       "[5770 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualcortex_bold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46bb71dd-5dfe-4dc4-a5fc-6b1d6de10a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualcortex_bold.to_csv('/home/jovyan/workingdirectory/visualcortex_bold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4d115-f58d-4b93-8eff-9624c3659fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lowlevel",
   "language": "python",
   "name": "lowlevel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
