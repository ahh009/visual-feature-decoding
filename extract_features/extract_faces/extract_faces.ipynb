{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91298ba5-ce32-4e1c-8d74-243598ba1ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### This notebook is a walkthrough of how to use extract_faces.py.\n",
    "\n",
    "You will need to have pliers and its face_recognition dependency installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f94e9-89a9-4702-9e0e-13666de3c451",
   "metadata": {},
   "source": [
    "To install, in command line run:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaf0c000-fafe-490a-8b7f-c2c14998d9d6",
   "metadata": {},
   "source": [
    "pip install pliers\n",
    "pip install face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ac29f-5739-4d0d-83a5-0b0929d2df9c",
   "metadata": {},
   "source": [
    "This script will read a features.json file that defines the frame sampling rate, the download path, and the save path.\n",
    "For convenience, this .json file should also include the other parameters you may need for extracting semantic or low-level visual features. Make sure that you specify where to find the movies with a complete file path, as well as where to save them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595476e2-c7e7-404d-9aaa-1575c97044bf",
   "metadata": {},
   "source": [
    "Note: You may want your sampling rate to match up with the TRs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8674e3a-d120-40a2-86be-fcdb70444054",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Here's an example of what should go in the .json file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e1f4e4-c097-4dfb-81e8-043ec8d8a9ec",
   "metadata": {},
   "source": [
    "\n",
    "{\"hcpmovies\": {  \n",
    "&emsp;      \"hdim\": 90,                ---> desired horizontal dimension of downsampled image  \n",
    "&emsp;      \"vdim\": 128,               ---> desired vertical dimension of downsampled image  \n",
    "&emsp;      \"fps\": 24,                 ---> frames per second of the movie\n",
    "&emsp;      \"dir\": [0, 30, 60,  90, 120, 150, 180, 210, 240, 270, 300, 330], ---> spatial directions of gabors (aka motion direction)  \n",
    "&emsp;      \"sf\": [0,4,8,16],               ---> spatial frequency range for gabors  \n",
    "&emsp;      \"tf\": [0,4],               ---> temporal frequency range for gabors  \n",
    "&emsp;      \"samplerate\": 1,           ---> the number of frames per second to sample  \n",
    "&emsp;      \"downloadpath\": \"/home/jovyan/shared/hcp-7T_Movies/movie/unzip/Post_20140821_version/\", ---> path to movies  \n",
    "&emsp;      \"movies\": [\"7T_MOVIE1_CC1_v2.mp4\", ---> list of movie names  \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE2_HO1_v2.mp4\",   \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE3_CC2_v2.mp4\",   \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE4_HO2_v2.mp4],\n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;   \n",
    "&emsp; \"savepath\": \"/home/jovyan/workingdirectory/\" ---> where you want to save features  \n",
    "&emsp;      \"TRs\": {\"7T_MOVIE1_CC1_v2\": {\"train1\": [20,265], \"train2\": [285,506], \"train3\": [526,714], \"train4\": [735,798], \"test1\":[818,901]},  \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE2_HO1_v2\": {\"train5\":[20,248],\"train6\":[267,526],\"train7\":[545,795],\"test2\":[815,898]},  \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE3_CC2_v2\": {\"train8\":[20,200],\"train9\": [220,405], \"train10\": [425,628], \"train11\": [650,793], \"test3\": [812,895]},  \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE4_HO2_v2\": {\"train12\":[20,254],\"train13\":[272,503],\"train14\":[522,777],\"test4\":[798,881]}  ---> list of movie names and the associated ranges of TRs to train and test on  \n",
    "&emsp; }  \n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff7254-0309-4016-90ad-eed5dbcec8ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Package installation\n",
    "Next, we import the packages we will need to extract and save out the features we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539c50a8-2049-471c-b54b-30e56a4de05d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:30:39.083746: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import face_recognition\n",
    "import pliers\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "from pliers.stimuli import VideoStim\n",
    "from pliers.graph import Graph\n",
    "from pliers.filters import FrameSamplingFilter\n",
    "from pliers.extractors import (FaceRecognitionFaceLocationsExtractor,\n",
    "                               FaceRecognitionFaceEncodingsExtractor,\n",
    "                               merge_results)\n",
    "\n",
    "from pliers.converters import VideoToAudioConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471402a3-bf8b-45b6-b2b1-88bdb7b852a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### To run the extractor in python notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96402d1c-dcf9-42f5-8cf2-d81d2b88b4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e8f34-1809-4687-abb2-cdd1a3c01fd3",
   "metadata": {},
   "source": [
    "#### JSON file path\n",
    "Your file path will need to be set to the specific json file you want to load in your parameters from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fe17e9-8ebe-44aa-9272-257ff5242327",
   "metadata": {},
   "source": [
    "Here is an example path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d50d894-f3ab-4d0e-8195-482967e35895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_filepath = '/home/jovyan/hackathon/visual-feature-decoding/extract_features/feature_AHH.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b82cb4-1d88-433c-a687-5ff026c79301",
   "metadata": {},
   "source": [
    "#### Extracting the face information\n",
    "This script will take in the movies as specified in your .json file, loop over them, and output an .npz file containing the extracted information. The .npz will contain, by column: \n",
    "\n",
    "[order, sample duration, time of face onset, face identity, coordinates of the bounding box for the identified face (in pixels)]\n",
    "\n",
    "The higher the sampling rate, the longer the extraction will take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a73cc2-f49b-48f8-8a74-1ab52e4f38c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stim: 921it [08:52,  1.73it/s]\n",
      "Stim: 918it [08:44,  1.75it/s]\n",
      "Stim: 915it [08:37,  1.77it/s]\n",
      "Stim: 901it [08:43,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "utils.extract_faces(json_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843d014-3fa2-4373-815d-a093961e727d",
   "metadata": {},
   "source": [
    "If you want to take a quick look at the saved data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "975dc957-92b5-44c8-8157-e0fb38121008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan 1.0 82.0 0 (204, 760, 590, 375)]\n",
      " [nan 1.0 84.0 0 (134, 812, 455, 491)]\n",
      " [nan 1.0 85.0 0 (76, 803, 461, 418)]\n",
      " ...\n",
      " [nan 1.0 895.0 2 (147, 250, 199, 199)]\n",
      " [nan 1.0 895.0 3 (155, 602, 229, 527)]\n",
      " [nan 1.0 895.0 4 (87, 467, 149, 405)]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load('/home/jovyan/hackathon/visual-feature-decoding/extract_features/extract_faces/extracted_data/7T_MOVIE1_CC1_v2_faces.npz', allow_pickle=True)\n",
    "\n",
    "# Access the arrays stored in the .npz file using keys\n",
    "features = data['features']\n",
    "print(features)\n",
    "\n",
    "# Close the file after using it\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311aa9c-bcdc-4aba-b6f6-fd909fe8c745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
