{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91298ba5-ce32-4e1c-8d74-243598ba1ff4",
   "metadata": {},
   "source": [
    "### This notebook is a walkthrough of how to use extract_faces.py.\n",
    "\n",
    "You will need to have pliers and its face_recognition dependency installed.\n",
    "In command line:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaf0c000-fafe-490a-8b7f-c2c14998d9d6",
   "metadata": {},
   "source": [
    "pip install pliers\n",
    "pip install face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ac29f-5739-4d0d-83a5-0b0929d2df9c",
   "metadata": {},
   "source": [
    "This script will read a features.json file that defines the frame sampling rate, the download path, and the save path.\n",
    "For convenience, this .json file should also include the other parameters you may need for extracting semantic or low-level visual features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8674e3a-d120-40a2-86be-fcdb70444054",
   "metadata": {},
   "source": [
    "#### Here's an example of what should go in the .json file:\n",
    "\n",
    "\n",
    "{\"hcpmovies\": {  \n",
    "&emsp;      \"hdim\": 90,                ---> desired horizontal dimension of downsampled image  \n",
    "&emsp;      \"vdim\": 128,               ---> desired vertical dimension of downsampled image  \n",
    "&emsp;      \"fps\": 24,                 ---> frames per second of the movie\n",
    "&emsp;      \"sd\": [0, 90, 180, 270],  ---> spatial directions of gabors (aka motion direction)  \n",
    "&emsp;      \"sf\": [0,4],               ---> spatial frequency range for gabors  \n",
    "&emsp;      \"tf\": [0,4],               ---> temporal frequency range for gabors  \n",
    "&emsp;      \"samplerate\": 2,           ---> the number of frames per second to sample\n",
    "&emsp;      \"downloadpath\": \"/home/jovyan/shared/hcp-7T_Movies/movie/unzip/Post_20140821_version/\", ---> path 2 movies  \n",
    "&emsp;      \"movies\": [\"7T_MOVIE1_CC1_v2.mp4\", ---> list of movie names  \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE2_HO1_v2.mp4\",   \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE3_CC2_v2.mp4\",   \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE4_HO2_v2.mp4],\n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;   \n",
    "&emsp; \"savepath\": \"/home/jovyan/workingdirectory/\" ---> where you want to save features  \n",
    "&emsp; }  \n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "539c50a8-2049-471c-b54b-30e56a4de05d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import face_recognition\n",
    "import pliers\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "from pliers.stimuli import VideoStim\n",
    "from pliers.graph import Graph\n",
    "from pliers.filters import FrameSamplingFilter\n",
    "#from pliers.extractors import (FaceRecognitionFaceLocationsExtractor,\n",
    "                               #FaceRecognitionFaceEncodingsExtractor,\n",
    "                               #MicrosoftAPIFaceExtractor,\n",
    "                               #GoogleVisionAPIFaceExtractor,\n",
    "                               #merge_results)\n",
    "from pliers.extractors import (FaceRecognitionFaceLocationsExtractor,\n",
    "                               FaceRecognitionFaceEncodingsExtractor,\n",
    "                               merge_results)\n",
    "\n",
    "from pliers.converters import VideoToAudioConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471402a3-bf8b-45b6-b2b1-88bdb7b852a0",
   "metadata": {},
   "source": [
    "In python notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96402d1c-dcf9-42f5-8cf2-d81d2b88b4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d50d894-f3ab-4d0e-8195-482967e35895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_filepath = '/home/jovyan/hackathon/visual-feature-decoding/extract_features/feature_AHH.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97ec9840-b10e-457c-967d-64ce5b1c7d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'face_recognition' from '/srv/conda/envs/notebook/lib/python3.10/site-packages/face_recognition/__init__.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pliers.utils.attempt_to_import('face_recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32a73cc2-f49b-48f8-8a74-1ab52e4f38c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stim: 918it [13:25,  1.14it/s]\n",
      "Stim: 901it [13:42,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "utils.extract_faces(json_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dc957-92b5-44c8-8157-e0fb38121008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
