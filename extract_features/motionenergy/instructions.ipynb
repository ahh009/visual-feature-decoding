{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed68752c-dbcd-40e1-837b-45ff83e805fd",
   "metadata": {},
   "source": [
    "## This notebook is a walkthrough of how to use extract_motion_energy.py.\n",
    "This script is a wrapper of [pymoten](https://gallantlab.org/pymoten/), and saves out an .npz file named \"me_features_all.npz\".  \n",
    "\n",
    "The first thing you need to do is make a features.json file that defines the parameters of your movie, the parameters of the gabor pyramid you want to use, the download path and the save path. This .json file is currently stored in extracted_features folder, one level up from /motionenergy.\n",
    "\n",
    "This script saves out:\n",
    "filters.npz --> list of dictionaries that describe the parameters of each gabor filter  \n",
    "me_features_all.npz --> all of the features for x_train and x_test  \n",
    "pyramid.obj --> the pyramid object itself  \n",
    "movie_gray.npz --> the gray matrix of the movie  \n",
    "movie_downsampledfeatures.npz -->  the TR-decimated, down-sampled features  \n",
    "movie_features.npz --> the features for each frame  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0ce28-3c44-411c-aacf-a892ec05702d",
   "metadata": {},
   "source": [
    "#### Here's an example of what should go in the .json file:  \n",
    "\n",
    "\n",
    "\n",
    "{\"hcpmovies\": {  \n",
    "&emsp;      \"hdim\": 90,                ---> desired horizontal dimension of downsampled image  \n",
    "&emsp;      \"vdim\": 128,               ---> desired vertical dimension of downsampled image  \n",
    "&emsp;      \"fps\": 24,                 ---> frames per second  \n",
    "&emsp;      \"sd\": [0, 90, 180, 270],  ---> spatial directions of gabors (aka motion direction)  \n",
    "&emsp;      \"sf\": [0,4],               ---> spatial frequency range for gabors  \n",
    "&emsp;      \"tf\": [0,4],               ---> temporal frequency range for gabors  \n",
    "&emsp;      \"downloadpath\": \"/home/jovyan/shared/hcp-7T_Movies/movie/unzip/Post_20140821_version/\", ---> path 2 movies  \n",
    "&emsp;      \"movies\": [\"7T_MOVIE1_CC1_v2.mp4\", ---> list of movie names  \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE2_HO1_v2.mp4\",   \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE3_CC2_v2.mp4\",   \n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;  \"7T_MOVIE4_HO2_v2.mp4],\n",
    "&emsp; &emsp; &emsp; &emsp; &emsp;   \n",
    "&emsp; \"savepath\": \"/home/jovyan/workingdirectory/\" ---> where you want to save features  \n",
    "&emsp; }  \n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cffc3c2-12a9-48ce-bfe7-b5628c6f9768",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Gabor pyramid notes\n",
    "The package that generates the gabor pyramid ([pymoten](https://gallantlab.org/pymoten/index.html)) uses hdim, vdim, spatial frequency (sf), temporal frequency (tf) and spatial directions (sd) parameters ([as well as a slew of other parameters](https://gallantlab.org/pymoten/autodoc/moten.pyramids.html#moten.pyramids.MotionEnergyPyramid)) to generate the full set of gabor filters used in the gabor pyramid.  \n",
    "  \n",
    "You can think of the gabor pyramid as being a huge set of filters with different spatial locations, sizes, orientations, spatial frequencies, and spatial directions (aka motion direction).  \n",
    "\n",
    "The spatial direction parameter corresponds to the direction of motion the filter prefers, which can be decomposed into orientation. For example, a filter with spatial direction 0ยบ and a filter with spatial direction 180ยบ have the same orientation (90ยบ).\n",
    "\n",
    "Pymoten pushes the stimuli through the gabor pyramid, and returns features that indicate the amount of motion energy signal passing through each filter at each frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd0589-8683-4b80-baa6-b0f3766020a6",
   "metadata": {},
   "source": [
    "#### Before running anything, you'll want to make a conda environment.  \n",
    "##### Here are the terminal calls I ran to make my conda environment called 'low-level':  \n",
    "\n",
    "1. This creates the conda environment called lowlevel with python 3.8. I'm using python 3.8 because of numpy deprecation issues.\n",
    "```\n",
    "conda create --name lowlevel python=3.8  \n",
    "```\n",
    "2. This installs all python-based packages\n",
    "```\n",
    "pip install numpy==1.20.1 matplotlib scikit-image scikit-video pymoten pillow==9.4.0 moviepy joblib\n",
    "```\n",
    "3. This installs conda packages\n",
    "```\n",
    "conda install ipykernel nb_conda_kernels jupyter  \n",
    "```\n",
    "4. This installs ffmpeg using the conda-forge channel\n",
    "```\n",
    "conda install -c conda-forge ffmpeg  \n",
    "```\n",
    "\n",
    "5. This step is important for making sure my lowlevel conda environment is available in jupyter hub notebook\n",
    "```\n",
    "python -m ipykernel install --user --name lowlevel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4d419-7c52-4e3d-b578-2a153514cdfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### If you want to use a python notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec358167-56e8-455c-869e-c4998d44d331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fcd3b63-b25e-4c8e-8a4c-25ba2d08f4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_filepath = '/home/jovyan/visual-feature-decoding/extract_features/feature.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf772f9-34ea-40a6-851b-245854f70796",
   "metadata": {},
   "source": [
    "the following function takes A LONG TIME to run!  \n",
    "the image resizing function is the bear -- roughly 1.5 hours for a 22k frame movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b83c92-64c7-447f-a86e-cef221cfd64f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7T_MOVIE1_CC1_v2 gray movie already exists!\n",
      "7T_MOVIE2_HO1_v2 gray movie already exists!\n",
      "7T_MOVIE3_CC2_v2 gray movie already exists!\n",
      "7T_MOVIE4_HO2_v2 gray movie already exists!\n"
     ]
    }
   ],
   "source": [
    "utils.movie_to_gray_array(json_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba3d4c-c5fa-48a7-9f35-eaa15004f858",
   "metadata": {},
   "source": [
    "After that's done, we can push the gray frames through the pyramid, and downsample to the TR  \n",
    "(24 frames --> 1 frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741a5e57-f0e7-48ed-8a41-baf2d66414f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved pyramid!\n",
      "saved filters!\n",
      "down_sampled features for 7T_MOVIE1_CC1_v2.mp4 already done!\n",
      "down_sampled features for 7T_MOVIE2_HO1_v2.mp4 already done!\n",
      "down_sampled features for 7T_MOVIE3_CC2_v2.mp4 already done!\n",
      "down_sampled features for 7T_MOVIE4_HO2_v2.mp4 already done!\n"
     ]
    }
   ],
   "source": [
    "utils.push_thru_pyramid(json_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc9b161-c9b5-47a8-8b6f-e5619a4193bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.save_cleaned_features(json_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4c9447-a413-4946-ad89-af6eb3650fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test = np.load(\"/home/jovyan/workingdirectory/me_features_all.npz\", allow_pickle=True)['x_test']\n",
    "x_train = np.load(\"/home/jovyan/workingdirectory/me_features_all.npz\", allow_pickle=True)['x_train']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465105e1-dc5e-43f3-8993-83e68447af0c",
   "metadata": {},
   "source": [
    "shape of x_test and x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95a5f77-89a0-4471-95d7-af7bded96f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1580, 83), (1580, 2885))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f841935b-4310-4b37-a38c-d495c76496bf",
   "metadata": {},
   "source": [
    "below shows the parameters for a single filter.  \n",
    "more info on filter paramters that we set can be found in json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e59f05a3-1f01-4aee-96de-04c5c1e39299",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'centerh': 0.7111111111111111,\n",
       " 'centerv': 0.5,\n",
       " 'direction': 0.0,\n",
       " 'spatial_freq': 4.0,\n",
       " 'spatial_env': 0.15,\n",
       " 'temporal_freq': 0.0,\n",
       " 'temporal_env': 0.3,\n",
       " 'filter_temporal_width': 16.0,\n",
       " 'aspect_ratio': 1.4222222222222223,\n",
       " 'stimulus_fps': 24.0,\n",
       " 'spatial_phase_offset': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"/home/jovyan/workingdirectory/filters.npz\", allow_pickle=True)['filters'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90113033-642f-4692-8b58-7e32192a3a71",
   "metadata": {},
   "source": [
    "#### if you want to call from the command line  \n",
    "\n",
    "1. first activate the conda environment!\n",
    "```\n",
    "conda activate lowlevel\n",
    "```  \n",
    "\n",
    "2. then run the following code in the terminal, replacing your json_filepath with the correct one :-)\n",
    "```\n",
    "python extract_motion_energy.py '/home/jovyan/visual-feature-decoding/extract_features/motionenergy/feature.json'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d75671-40b9-4022-b41c-6b4bb9340ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lowlevel",
   "language": "python",
   "name": "lowlevel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
